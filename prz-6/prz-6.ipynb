{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическая работа №6. Атака по переносу (Transfer attack) на модели ИИ\n",
    "\n",
    "Выполнил Сердюков Матвей, ББМО-01-23\n",
    "\n",
    "## Цель задания\n",
    "\n",
    "Изучить концепцию атаки по переносу, где противоречивые примеры, созданные для одной модели,\n",
    "используются для атаки на другую модель. Это задание требует создания нескольких моделей,\n",
    "генерации противоречивых примеров для одной модели и проверки их на другой модели.\n",
    "\n",
    "## Задачи\n",
    "\n",
    "1. Загрузить несколько моделей, обученных на датасете MNIST.\n",
    "2. Изучить теоретические основы атаки по переносу.\n",
    "3. Реализовать атаку FGSM на одну модель и проверить, как противоречивые примеры влияют на\n",
    "другую модель.\n",
    "4. Оценить точность обеих моделей на противоречивых примерах и проанализировать\n",
    "переносимость атак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и создание двух различных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 19:17:17.093989: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-20 19:17:17.262392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-20 19:17:17.328913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-20 19:17:17.345899: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 19:17:17.467226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-20 19:17:18.627446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/baksist/.virtualenvs/aszii/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734711440.077886    2103 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-20 19:17:20.195598: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.4353\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.1155\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9782 - loss: 0.0748\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9829 - loss: 0.0574\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9883 - loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baksist/.virtualenvs/aszii/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.3143\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0528\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0285\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0183\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Загрузка данных MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Нормализация данных\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Преобразование меток в one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Модель 1: Простая полносвязная нейронная сеть\n",
    "model1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model1.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Сохранение модели\n",
    "model1.save('mnist_model1.h5')\n",
    "\n",
    "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
    "model2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
    "\n",
    "# Сохранение модели\n",
    "model2.save('mnist_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация атаки FGSM на первую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Функция FGSM атаки\n",
    "def fgsm_attack(image, epsilon, gradient):\n",
    "    # Применение знака градиента к изображению\n",
    "    perturbed_image = image + epsilon * np.sign(gradient)\n",
    "    perturbed_image = np.clip(perturbed_image, 0, 1) # Убедиться, что значения остаются в пределах [0, 1]\n",
    "    return perturbed_image\n",
    "# Генерация противоречивых примеров для первой модели\n",
    "def generate_fgsm_adversarial(model, images, labels, epsilon):\n",
    "    adversarial_images = []\n",
    "    for i in range(len(images)):\n",
    "        #image = images[i].reshape(1, 28, 28, 1)\n",
    "        image = tf.convert_to_tensor(images[i].reshape((1, 28, 28, 1)))\n",
    "        #label = labels[i]\n",
    "        label = tf.convert_to_tensor(labels[i])\n",
    "        # Вычисление градиента\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(image)\n",
    "            prediction = model(image)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        adv_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
    "        adversarial_images.append(adv_image.reshape(28, 28))\n",
    "    return np.array(adversarial_images)\n",
    "# Генерация противоречивых примеров для первой модели\n",
    "epsilon = 0.1\n",
    "adversarial_images_model1 = generate_fgsm_adversarial(model1, test_images, test_labels, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка противоречивых примеров на обеих моделях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.0989 - loss: 6.2114\n",
      "Accuracy of model1 on adversarial examples: 0.12520000338554382\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1441\n",
      "Accuracy of model2 on adversarial examples from model1: 0.9652000069618225\n"
     ]
    }
   ],
   "source": [
    "# Оценка первой модели на противоречивых примерах\n",
    "test_labels_argmax = np.argmax(test_labels, axis=1) # Преобразование one-hot меток в целые числа\n",
    "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
    "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
    "\n",
    "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
    "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
    "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
    "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ переносимости атак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.9494 - loss: 0.1592\n",
      "Accuracy of model1 on adversarial examples from model2: 0.9549999833106995\n"
     ]
    }
   ],
   "source": [
    "# Генерация противоречивых примеров для второй модели\n",
    "adversarial_images_model2 = generate_fgsm_adversarial(model2, test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
    "\n",
    "# Оценка первой модели на противоречивых примерах второй модели\n",
    "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28, 28), test_labels)\n",
    "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Осуществив FGSM-атаку на первую модель, сгенерированные примеры также смогли повлиять на вторую модель, однако, в значительно меньшей степени. Если для первой модели точность на противоречивых примерах составила 9,9%, то у второй модели точность упала лишь до 95%. Аналогичное поведение можно наблюдать и в обратной ситуации, применив противоречивые примеры второй модели для первой.\n",
    "\n",
    "Таким образом, атака по переносу позволяет использовать одни и те же противоречивые примеры для разных моделей, но с разной степенью эффективности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aszii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
